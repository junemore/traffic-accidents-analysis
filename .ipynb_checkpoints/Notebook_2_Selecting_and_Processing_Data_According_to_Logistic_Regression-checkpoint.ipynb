{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dbfread import DBF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import shelve\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 10 years of accident data, from 2007 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load accidents data from 2007 to 2016 \n",
    "dbf07= DBF('accident/accident2007.dbf')\n",
    "dbf08= DBF('accident/accident2008.dbf')\n",
    "dbf09= DBF('accident/accident2009.dbf')\n",
    "dbf10= DBF('accident/accident2010.dbf')\n",
    "dbf11 = DBF('accident/accident2011.dbf')\n",
    "dbf12 = DBF('accident/accident2012.dbf')\n",
    "dbf13 = DBF('accident/accident2013.dbf')\n",
    "dbf14 = DBF('accident/accident2014.dbf')\n",
    "dbf15 = DBF('accident/accident2015.dbf')\n",
    "dbf16 = DBF('accident/accident2016.dbf')\n",
    "accidents07 = DataFrame(iter(dbf07))\n",
    "accidents08 = DataFrame(iter(dbf08))\n",
    "accidents09 = DataFrame(iter(dbf09))\n",
    "accidents10 = DataFrame(iter(dbf10))\n",
    "accidents11 = DataFrame(iter(dbf11))\n",
    "accidents12 = DataFrame(iter(dbf12))\n",
    "accidents13 = DataFrame(iter(dbf13))\n",
    "accidents14 = DataFrame(iter(dbf14))\n",
    "accidents15 = DataFrame(iter(dbf15))\n",
    "accidents16 = DataFrame(iter(dbf16))\n",
    "# The column name 'latitude' and 'longitud' in accidents07 are different from other dataframes, so we rename these 2 columns to match column names in other dataframes\n",
    "accidents07.rename(columns={'latitude': 'LATITUDE', 'longitud': 'LONGITUD'}, inplace=True)\n",
    "allaccidents = pd.concat([accidents07,accidents08,accidents09,accidents10,accidents11,accidents12,accidents13,accidents14,accidents15,accidents16], axis=0,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load vehicle data from 2007 to 2016 \n",
    "vdbf07= DBF('vehicle_deaths/vehicle2007.dbf')\n",
    "vdbf08= DBF('vehicle_deaths/vehicle2008.dbf')\n",
    "vdbf09= DBF('vehicle_deaths/vehicle2009.dbf')\n",
    "vdbf10= DBF('vehicle_deaths/vehicle2010.dbf')\n",
    "vdbf11= DBF('vehicle_deaths/vehicle2011.dbf')\n",
    "vdbf12= DBF('vehicle_deaths/vehicle2012.dbf')\n",
    "vdbf13= DBF('vehicle_deaths/vehicle2013.dbf')\n",
    "vdbf14= DBF('vehicle_deaths/vehicle2014.dbf')\n",
    "vdbf16= DBF('vehicle_deaths/vehicle2016.dbf')\n",
    "vehicle07 = DataFrame(iter(vdbf07))\n",
    "vehicle08 = DataFrame(iter(vdbf08))\n",
    "vehicle09 = DataFrame(iter(vdbf09))\n",
    "vehicle10 = DataFrame(iter(vdbf10))\n",
    "vehicle11 = DataFrame(iter(vdbf11))\n",
    "vehicle12 = DataFrame(iter(vdbf12))\n",
    "vehicle13 = DataFrame(iter(vdbf13))\n",
    "vehicle14 = DataFrame(iter(vdbf14))\n",
    "vehicle15 = pd.read_csv('vehicle_deaths/vehicle2015.csv',encoding = \"ISO-8859-1\")\n",
    "vehicle16 = DataFrame(iter(vdbf16))\n",
    "#adding a column of YEAR in each vehicle dataframe\n",
    "vehicle07['YEAR']=2007\n",
    "vehicle08['YEAR']=2008\n",
    "vehicle09['YEAR']=2009\n",
    "vehicle10['YEAR']=2010\n",
    "vehicle11['YEAR']=2011\n",
    "vehicle12['YEAR']=2012\n",
    "vehicle13['YEAR']=2013\n",
    "vehicle14['YEAR']=2014\n",
    "vehicle15['YEAR']=2015\n",
    "vehicle16['YEAR']=2016\n",
    "allvehicles=pd.concat([vehicle07,vehicle08,vehicle09,vehicle10,vehicle11,vehicle12,vehicle13,vehicle14,vehicle15,vehicle16], axis=0,join='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to combine accidents10 ~ accidents16 to one dataframe. Since not all of the accident data downloaded from the U.S. Department of Transportation have the same features, by using the `jion:inner` option in `pd.concat` function, we can get the intersection of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The allaccidents table recorded 320874 accidents from 2010-2016, and it has 42 features. Here are the meaning of some of the features according to the `FARS Analytical User’s Manual`.\n",
    "\n",
    "### Explaination of variables\n",
    "*VE_TOTAL*: Number of Vehicle in crash <br/>\n",
    "*VE_FORMS*: Number of Motor Vehicles in Transport (MVIT) <br/>\n",
    "*PED*: Number of Persons Not in Motor Vehicles <br/>\n",
    "*NHS*: National Highway System<br/>\n",
    "*ROUTE*: Route Signing <br/>\n",
    "*SP_JUR*: Special Jurisdiction <br/>\n",
    "*HARM_EV*: First Harmful Event<br/>\n",
    "*TWAY_ID , TWAY_ID2* : Trafficway Identifier <br/>\n",
    "*MILEPT*: Milepoint <br/>\n",
    "*SP_JUR*: Special Jurisdiction<br/>\n",
    "*HARM_EV*: injury or damage producing First Harmful Event <br/> \n",
    "*MAN_COLL*:Manner of Collision  <br/> \n",
    "*RELJCT1, RELJCT2*: Relation to Junction- Within Interchange Area, Specific Location. <br/>\n",
    "*TYP_INT*: Type of Intersection <br/>\n",
    "*REL_ROAD*: Relation to Trafficway <br/>\n",
    "*LGT_COND*: Light Condition<br/> \n",
    "*NOT_HOUR,MIN*: Min, Hour of Notification <br/>\n",
    "*ARR_HOUR,MIN*: Hour, Min arrival at scene <br/>\n",
    "*HOSP_HR,MIN*: Hour, Min arrival at hospital <br/>\n",
    "*CF1, CF2, CF3*:Related Factors- Crash Level, factors related to the crash <br/>\n",
    "*FATALS*: Fatalities<br/>\n",
    "*DRUNK_DR*: Number of Drinking Drivers<br/> \n",
    "*RAIL*: Rail Grade Crossing Identifier<br/>\n",
    "\n",
    "For more detailed information, please refer to `FARS Analytical User’s Manual`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select variables and rename variables\n",
    "Observed from the table above, some of the variables in the table are not very readable. Therefore, in order to make it easier to understand the variables,we renamed some of the variables according to `FARS Analytical User’s Manual`  downloaded from the  `U.S. Department of Transportation`  website. In order to make all column values informative, we selected important column variables from allaccidents, replace numerical number to meaningful character description according to `FARS Analytical User’s Manual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "accidents = allaccidents[['YEAR','ST_CASE','STATE','VE_TOTAL','FATALS','MONTH','DAY_WEEK','HOUR','NHS','LATITUDE','LONGITUD','MAN_COLL','LGT_COND','WEATHER','CF1','DRUNK_DR']]\n",
    "accidents.rename(columns={'ST_CASE':'CASE_NUM','VE_TOTAL':'NUM_VEHICLE','NHS': 'HIGHWAY', 'MAN_COLL': 'COLLISION_TYPE','LGT_COND':'LIGHT_CONDITION','CF1':'CRASH_FACTOR','DRUNK_DR':'DRUNK_DRIVE'}, inplace=True)\n",
    "accidents['MONTH'] = accidents['MONTH'].map({1.0:'January', 2.0:'February', 3.0: 'March', 4.0:'April', 5.0:'May', 6.0:'June', 7.0:'July', 8.0:'August',9.0: 'September', 10.0:'October', 11.0:'November', 12.0:'December'})\n",
    "accidents['DAY_WEEK']= accidents['DAY_WEEK'].map({1.0:'Sunday',2.0:'Monday', 3.0:'Tuesday', 4.0: 'Wednesday', 5.0:'Thursday', 6.0:'Friday', 7.0:'Saturday'})\n",
    "accidents['HIGHWAY'] = accidents['HIGHWAY'].map({1.0:'On',0.0:'Off',9.0:'Unknow'})\n",
    "accidents['COLLISION_TYPE'] = accidents['COLLISION_TYPE'].map({0.0:'Not Collision',1.0:'Rear-End',2.0:'Head-On',3.0:'Rear-to-Rear',4.0:'Angle',5.0:'Sideswipe, Same Direction',6.0:'Sideswipe, Opposite Direction',7.0:'Sideswipe, Unknown Direction',9.0:'Unknown'})\n",
    "accidents['LIGHT_CONDITION'] = accidents['LIGHT_CONDITION'].map({1.0:'Daylight',2.0:'Dark' ,3.0:'Dark',5.0:'Dusk',6.0:'Dark',4.0:'Dawn', 7.0:'Other',8.0 :'Not Report', 9.0:'Not Report'})\n",
    "accidents['WEATHER'] = accidents['WEATHER'].map({0.0:'Normal',1.0:'Clear',2.0:'Rain', 3.0: 'Sleet,Hail', 4.0:'Snow', 5.0:'Fog, Smog, Smoke',6.0:'Severe Crosswinds',7.0:'Blowing Sand, Soil, Dirt',8.0:'other',10.0:'Cloudy',11.0:'Blowing Snow',12.0:'Freezing Rain or Drizzle',98.0:'Not Reported', 99.0:'Unkown' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicles = allvehicles[['STATE','YEAR','ST_CASE','TRAV_SP','ROLLOVER','FIRE_EXP','BODY_TYP','SPEEDREL','DEATHS','DR_DRINK']]\n",
    "vehicles.rename(columns={'ST_CASE':'CASE_NUM','TRAV_SP':'SPEED','FIRE_EXP': 'FIRE','SPEEDREL':'SPEEDING','DR_DRINK':'DRINKING_INDICATOR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_index(df):\n",
    "    df['STATE']=df['STATE'].astype(int)\n",
    "    df['CASE_NUM']=df['CASE_NUM'].astype(int)\n",
    "    df['YEAR']=df['YEAR'].astype(int)\n",
    "    df.index = list(df['YEAR'].astype(str) + df['CASE_NUM'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=[accidents,vehicles]\n",
    "for s in df:\n",
    "    make_index(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "combine \"year\" and \"case_num\" to reindex accidents dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.read_hdf('results/person.h5', 'person')\n",
    "person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatal_crashs = pd.merge(vehicles, accidents, left_index=True, right_index=True, how='inner',on=('STATE', 'YEAR','CASE_NUM'))\n",
    "fatal_crashs_all = pd.merge(fatal_crashs,person,on=('STATE', 'YEAR','CASE_NUM'))\n",
    "fatal_crashs_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fatal_crashs.to_hdf('results/fatal_crashs.h5', 'fatal_crashs')\n",
    "accidents.to_hdf('results/accidents.h5', 'accidents')\n",
    "vehicles.to_hdf('results/vehicles.h5', 'vehicles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vehicle data file which contains mortality rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to study the mortality rate of fatal accidents. The data element “Fatalities in Vehicle” in the Vehicle data file from the `U.S. Department of Transportation` website provides the number of deaths in a vehicle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
